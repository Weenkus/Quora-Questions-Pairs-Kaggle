{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import spacy\n",
    "from collections import defaultdict\n",
    "from scipy.stats import describe\n",
    "from spacy.symbols import nsubj, dobj\n",
    "\n",
    "nlp = spacy.load('en_default')  # using en_core_web_md model\n",
    "\n",
    "\n",
    "def train_set(size=404301):\n",
    "    with open('input/train.csv', 'r') as input_file:\n",
    "        reader = csv.DictReader(input_file)\n",
    "        for counter, line in enumerate(reader):\n",
    "            if counter >= size:\n",
    "                break\n",
    "            yield int(line['id']), line['question1'], line['question2'], int(line['is_duplicate'])\n",
    "\n",
    "\n",
    "def precalculated_predictions():\n",
    "    predictions = dict()\n",
    "\n",
    "    with open('input/trian_predictions_0_324.csv') as input_file:\n",
    "        reader = csv.DictReader(input_file)\n",
    "        for line in reader:\n",
    "            predictions[int(line['train_id'])] = float(line['probability'])\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get false prediction examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the step by step guide to invest in share market in india?\nWhat is the step by step guide to invest in share market?\n0.683279\nFalse\n-------------------\nWhich one dissolve in water quikly sugar, salt, methane and carbon di oxide?\nWhich fish would survive in salt water?\n0.848533\nFalse\n-------------------\nShould I buy tiago?\nWhat keeps childern active and far from phone and video games?\n0.842406\nFalse\n-------------------\nWhen do you use シ instead of し?\nWhen do you use \"&\" instead of \"and\"?\n0.894469\nFalse\n-------------------\nMethod to find separation of slits using fresnel biprism?\nWhat are some of the things technicians can tell about the durability and reliability of Laptops and its components?\n0.968832\nFalse\n-------------------\nHow do I read and find my YouTube comments?\nHow can I see all my Youtube comments?\n0.520986\nTrue\n-------------------\nWhat was your first sexual experience like?\nWhat was your first sexual experience?\n0.974132\nTrue\n-------------------\nWhat would a Trump presidency mean for current international master’s students on an F1 visa?\nHow will a Trump presidency affect the students presently in US or planning to study in US?\n0.99053\nTrue\n-------------------\nWhy do rockets look white?\nWhy are rockets and boosters painted white?\n0.975512\nTrue\n-------------------\nWhat are some tips on making it through the job interview process at Medicines?\nWhat are some tips on making it through the job interview process at Foundation Medicine?\n0.867693\nFalse\n-------------------\nDoes society place too much importance on sports?\nHow do sports contribute to the society?\n0.932451\nFalse\n-------------------\nHow should I prepare for CA final law?\nHow one should know that he/she completely prepare for CA final exam?\n0.891444\nTrue\n-------------------\nWhat are some special cares for someone with a nose that gets stuffy during the night?\nHow can I keep my nose from getting stuffy at night?\n0.934857\nTrue\n-------------------\nWhen a girlfriend asks her boyfriend \"Why did you choose me? What makes you want to be with me?\", what should one reply to her?\nMy girlfriend said that we should end this because she is confused about her feelings for me. I wished her well and disconnected. Should I call her and ask her if she wants to get back together?\n0.520918\nFalse\n-------------------\nWhat is the stall speed and AOA of an f-14 with wings fully swept back?\nWhy did aircraft stop using variable-sweep wings, like those on an F-14?\n0.754036\nFalse\n-------------------\nWhen can I expect my Cognizant confirmation mail?\nWhen can I expect Cognizant confirmation mail?\n0.976572\nFalse\n-------------------\nIs being a good kid and not being a rebel worth it in the long run?\nIs being bored good for a kid?\n0.962967\nFalse\n-------------------\nWhat universities does Rexnord recruit new grads from? What majors are they looking for?\nWhat universities does B&G Foods recruit new grads from? What majors are they looking for?\n0.925187\nFalse\n-------------------\nHow did Darth Vader fought Darth Maul in Star Wars Legends?\nDoes Quora have a character limit for profile descriptions?\n0.737162\nFalse\n-------------------\nWhat are some examples of products that can be make from crude oil?\nWhat are some of the products made from crude oil?\n0.983538\nTrue\n-------------------\nHow do I make friends.\nHow to make friends ?\n0.735025\nTrue\n-------------------\nWhat is the best/most memorable thing you've ever eaten and why?\nWhat is the most delicious dish you've ever eaten and why?\n0.707379\nTrue\n-------------------\nWho is israil friend?\nIs my boyfriend lying about his true feelings for his friend and is he secretly attracted to her?\n0.841978\nFalse\n-------------------\nWhat are some good rap songs to dance to?\nWhat are some of the best rap songs?\n0.623635\nFalse\n-------------------\nHow do I download content from a kickass torrent without registration?\nIs Kickass Torrents trustworthy?\n0.840083\nFalse\n-------------------\nHow is the new Harry Potter book 'Harry Potter and the Cursed Child'?\nHow bad is the new book by J.K Rowling?\n0.977953\nTrue\n-------------------\nWhy do I always get depressed?\nWhy do I always get depressed in the evening?\n0.745671\nFalse\n-------------------\nWhere can I find a European family office database?\nWhere do I find a U.S. family office database?\n0.910421\nFalse\n-------------------\nWhat is Java programming? How To Learn Java Programming Language ?\nHow do I learn a computer language like java?\n0.78444\nTrue\n-------------------\nWhat is the best book ever made?\nWhat is the most important book you have ever read?\n0.827429\nTrue\n-------------------\nCan we ever store energy produced in lightning?\nIs it possible to store the energy of lightning?\n0.993421\nTrue\n-------------------\nAt what cost does so much privacy as in Germany come? What else is lost to gain so much privacy?\nAre there any people who genuinely enjoy salad with no dressing?\n0.823944\nFalse\n-------------------\nWhat is a narcissistic personality disorder?\nWhat is narcissistic personality disorder?\n0.984175\nTrue\n-------------------\nHow I can speak English fluently?\nHow can I learn to speak English fluently?\n0.7484930000000001\nTrue\n-------------------\nHow can I make money through the Internet?\nWhat are some different ways to make money online, excluding selling things?\n0.922443\nFalse\n-------------------\nWhat is purpose of life?\nWhat's the purpose of life? What is life actually about?\n0.994749\nTrue\n-------------------\nWhen will the BJP government strip all the Muslims and the Christians of the Indian citizenship and put them on boats like the Rohingya's of Burma?\nWhy India does not apply the \"Burma-Rohingya model\" to deport illegal Bangladeshis?\n0.572342\nFalse\n-------------------\nIf someone wants to open a commercial FM radio station in any city of India, how much does it cost and what is the procedure?\nI want to make a travel commercial/clip video HD , For India and New Zealand. How much will it cost?\n0.796091\nFalse\n-------------------\nWhat were the major effects of the cambodia earthquake, and how do these effects compare to the Kamchatca earthquakes in 1952?\nWhat were the major effects of the cambodia earthquake, and how do these effects compare to the Valparaiso earthquake in 1822?\n0.991774\nTrue\n-------------------\nWhat are some of the best romantic movies in English?\nWhat is the best romantic movie you have ever seen?\n0.928765\nTrue\n-------------------\nWhy did harry become a horcrux?\nWhat is a Horcrux?\n0.88864\nFalse\n-------------------\nWhat are the best associate product manager (APM) programs that someone in their early 20s can join to learn product management and have a rewarding career in the company?\nWhat are the general requirement to become a Product Manager or a Program Manager in a product based software company?\n0.557084\nFalse\n-------------------\n"
     ]
    }
   ],
   "source": [
    "predictions = precalculated_predictions()\n",
    "\n",
    "for pair_id, question1, question2, is_duplicate in train_set(100):\n",
    "    if abs(predictions[pair_id] - is_duplicate) > 0.5:\n",
    "        print('%s\\n%s\\n%s\\n%s\\n-------------------' % (question1, question2, abs(predictions[pair_id] - is_duplicate), bool(is_duplicate)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subjects(question):\n",
    "    return set([word.lemma_ for word in question if word.dep == nsubj])\n",
    "\n",
    "\n",
    "def get_objects(question):\n",
    "    return set([word.lemma_ for word in question if word.dep == dobj])\n",
    "\n",
    "\n",
    "def get_roots(question):\n",
    "    return set([word.lemma_ for word in question if word.dep_ == 'ROOT'])\n",
    "\n",
    "\n",
    "def get_heads(question):\n",
    "    return set([word.head.lemma_ for word in question])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUBJECTS\n{'step'}\n{'step'}\n-------------------\nset()\n{'fish'}\n-------------------\n{'-PRON-'}\n{'what'}\n-------------------\n{'-PRON-'}\n{'-PRON-'}\n-------------------\nset()\n{'some', 'technician'}\n-------------------\n{'tip'}\n{'tip'}\n-------------------\nset()\n{'sport'}\n-------------------\n{'-PRON-', 'boyfriend', 'what', 'girlfriend'}\n{'-PRON-', 'girlfriend'}\n-------------------\nset()\n{'aircraft'}\n-------------------\n{'-PRON-'}\n{'-PRON-'}\n-------------------\nset()\nset()\n-------------------\n{'university', 'rexnord', '-PRON-'}\n{'foods', '-PRON-'}\n-------------------\n{'vader'}\n{'quora'}\n-------------------\n{'who'}\n{'boyfriend', '-PRON-'}\n-------------------\n{'what'}\n{'some'}\n-------------------\n{'-PRON-'}\n{'torrent'}\n-------------------\n{'-PRON-'}\n{'-PRON-'}\n-------------------\n{'-PRON-'}\n{'-PRON-'}\n-------------------\n{'cost'}\n{'who'}\n-------------------\n{'-PRON-'}\n{'way'}\n-------------------\n{'government'}\n{'india'}\n-------------------\n{'procedure', 'someone', '-PRON-'}\n{'-PRON-'}\n-------------------\n{'harry'}\n{'what', 'horcrux'}\n-------------------\n{'someone'}\nset()\n-------------------\n\n\nOBJECTS\nset()\nset()\n-------------------\n{'sugar'}\nset()\n-------------------\n{'tiago'}\nset()\n-------------------\n{'シ'}\nset()\n-------------------\n{'separation', 'biprism'}\nset()\n-------------------\n{'-PRON-'}\n{'-PRON-'}\n-------------------\n{'place', 'importance'}\nset()\n-------------------\n{'-PRON-'}\n{'this', '-PRON-'}\n-------------------\nset()\n{'wing'}\n-------------------\n{'mail'}\n{'mail'}\n-------------------\nset()\nset()\n-------------------\n{'what', 'grad'}\n{'university', 'grad'}\n-------------------\n{'maul'}\n{'limit'}\n-------------------\nset()\nset()\n-------------------\nset()\nset()\n-------------------\n{'content'}\nset()\n-------------------\nset()\nset()\n-------------------\n{'database'}\n{'office'}\n-------------------\n{'privacy'}\n{'salad'}\n-------------------\n{'money'}\n{'thing', 'money'}\n-------------------\n{'muslims', '-PRON-'}\n{'model', 'bangladeshis'}\n-------------------\n{'much', 'station'}\n{'hd', 'much'}\n-------------------\nset()\nset()\n-------------------\n{'career', 'that', 'management'}\nset()\n-------------------\n\n\nROOTS\n{'be'}\n{'be'}\n-------------------\n{'dissolve'}\n{'survive'}\n-------------------\n{'buy'}\n{'keep'}\n-------------------\n{'use'}\n{'use'}\n-------------------\n{'method'}\n{'be'}\n-------------------\n{'be'}\n{'be'}\n-------------------\n{'do'}\n{'contribute'}\n-------------------\n{'reply', 'choose', 'make'}\n{'say', 'wish', 'call'}\n-------------------\n{'be'}\n{'stop'}\n-------------------\n{'expect'}\n{'expect'}\n-------------------\n{'be'}\n{'be'}\n-------------------\n{'recruit', 'look'}\n{'recruit', 'look'}\n-------------------\n{'fight'}\n{'have'}\n-------------------\n{'be'}\n{'lie'}\n-------------------\n{'be'}\n{'be'}\n-------------------\n{'download'}\n{'be'}\n-------------------\n{'get'}\n{'get'}\n-------------------\n{'find'}\n{'find'}\n-------------------\n{'come', 'lose'}\n{'be'}\n-------------------\n{'make'}\n{'be'}\n-------------------\n{'strip'}\n{'apply'}\n-------------------\n{'cost'}\n{'cost', 'want'}\n-------------------\n{'become'}\n{'be'}\n-------------------\n{'be'}\n{'be'}\n-------------------\n\n\nHEADS\n{'guide', 'by', 'in', 'invest', 'be', 'step', 'market'}\n{'guide', 'by', 'in', 'invest', 'be', 'step', 'market'}\n-------------------\n{'one', 'carbon', 'in', 'dissolve', 'sugar', 'salt', 'methane'}\n{'survive', 'water', 'in', 'fish'}\n-------------------\n{'buy'}\n{'active', 'game', 'from', 'phone', 'far', 'keep'}\n-------------------\n{'of', 'シ', 'use'}\n{'of', 'use'}\n-------------------\n{'separation', 'use', 'method', 'find', 'of', 'biprism'}\n{'component', 'laptop', 'be', 'some', 'thing', 'of', 'tell', 'about', 'durability'}\n-------------------\n{'on', 'make', 'be', 'interview', 'at', 'process', 'through', 'tip'}\n{'on', 'make', 'medicine', 'be', 'interview', 'at', 'process', 'through', 'tip'}\n-------------------\n{'do', 'on', 'place', 'much', 'importance'}\n{'to', 'contribute', 'society'}\n-------------------\n{'to', 'boyfriend', 'make', 'with', 'choose', 'be', 'reply', 'want', 'ask', 'girlfriend'}\n{'end', 'call', 'confused', 'for', 'get', 'be', 'wish', 'want', 'feeling', 'say', 'about', 'ask', 'girlfriend'}\n-------------------\n{'sweep', 'with', 'f-14', 'be', 'of', 'speed'}\n{'like', 'on', 'wing', 'sweep', 'stop', 'f-14', 'use', 'those'}\n-------------------\n{'expect', 'mail', 'confirmation'}\n{'expect', 'mail'}\n-------------------\n{'run', 'worth', 'in', 'kid', 'be'}\n{'for', 'good', 'kid', 'be'}\n-------------------\n{'look', 'major', 'recruit', 'grad'}\n{'foods', 'recruit', 'look', 'grad', 'major', 'university'}\n-------------------\n{'vader', 'wars', 'in', 'fight', 'legends', 'maul'}\n{'for', 'limit', 'description', 'have'}\n-------------------\n{'friend', 'be'}\n{'to', 'friend', 'boyfriend', 'attract', 'for', 'be', 'feeling', 'lie', 'about'}\n-------------------\n{'dance', 'song', 'be'}\n{'of', 'some', 'song', 'be'}\n-------------------\n{'torrent', 'from', 'without', 'download'}\n{'torrent', 'be'}\n-------------------\n{'get'}\n{'get', 'in', 'depressed', 'evening'}\n-------------------\n{'find', 'database', 'office'}\n{'find', 'office'}\n-------------------\n{'come', 'lose', 'gain', 'in', 'what', 'much', 'do', 'as', 'privacy', 'cost'}\n{'with', 'people', 'dressing', 'enjoy', 'be'}\n-------------------\n{'internet', 'make', 'through'}\n{'sell', 'way', 'exclude', 'make', 'be'}\n-------------------\n{'like', 'on', 'put', 'boat', 'christians', 'rohingya', 'muslims', 'strip', 'of', 'government', 'citizenship'}\n{'model', 'deport', 'rohingya', 'bangladeshis', 'apply'}\n-------------------\n{'procedure', 'in', 'much', 'station', 'be', 'city', 'want', 'open', 'of', 'cost'}\n{'make', 'for', 'zealand', 'video', 'hd', 'much', 'india', 'want', 'clip', 'cost'}\n-------------------\n{'become', 'horcrux'}\n{'horcrux', 'be'}\n-------------------\n{'join', 'someone', 'management', 'career', 'manager', 'in', '20', 'have', 'be', 'learn', 'company', 'program'}\n{'in', 'manager', 'product', 'be', 'become', 'company', 'requirement'}\n-------------------\n"
     ]
    }
   ],
   "source": [
    "subjects = list()\n",
    "objects = list()\n",
    "roots = list()\n",
    "heads = list()\n",
    "\n",
    "for pair_id, question1, question2, is_duplicate in train_set(100):\n",
    "    if abs(predictions[pair_id] - is_duplicate) > 0.5 and not is_duplicate:\n",
    "        question1_doc = nlp(question1)\n",
    "        question2_doc = nlp(question2)\n",
    "        \n",
    "        subjects.append((get_subjects(question1_doc), get_subjects(question2_doc)))\n",
    "        objects.append((get_objects(question1_doc), get_objects(question2_doc)))\n",
    "        roots.append((get_roots(question1_doc), get_roots(question2_doc)))\n",
    "        heads.append((get_heads(question1_doc), get_heads(question2_doc)))\n",
    "\n",
    "print('SUBJECTS')\n",
    "for pair in subjects:\n",
    "    print('%s\\n%s\\n-------------------' % pair)\n",
    "\n",
    "print('\\n\\nOBJECTS')\n",
    "for pair in objects:\n",
    "    print('%s\\n%s\\n-------------------' % pair)\n",
    "\n",
    "print('\\n\\nROOTS')\n",
    "for pair in roots:\n",
    "    print('%s\\n%s\\n-------------------' % pair)\n",
    "\n",
    "print('\\n\\nHEADS')\n",
    "for pair in heads:\n",
    "    print('%s\\n%s\\n-------------------' % pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_index(set1, set2):\n",
    "    if len(set1) == 0 and len(set2) == 0:\n",
    "        return 1.0\n",
    "    return len(set1 & set2) / len(set1 | set2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tnumber of observations\t(minimum, maximum)\tmean\tvariance\tskewness\tkurtosis\nSUBJECTS\nDUPLICATE:\t 37254\t(0.0, 1.0)\t0.520536944579\t0.218928498626\t-0.07258566702361444\t-1.860007775243315\nNOT DUPLICATE:\t 62746\t(0.0, 1.0)\t0.370059015967\t0.199678019125\t0.5534414840760108\t-1.5232534084683247\n\nOBJECTS\nDUPLICATE:\t 37254\t(0.0, 1.0)\t0.669082131161\t0.203801192924\t-0.7102806989927335\t-1.4021024803067506\nNOT DUPLICATE:\t 62746\t(0.0, 1.0)\t0.473461813034\t0.236205047528\t0.11384966274387981\t-1.9352000411457764\n\nROOTS\nDUPLICATE:\t 37254\t(0.0, 1.0)\t0.59802379802\t0.225224956912\t-0.39604874810104057\t-1.7746373433805054\nNOT DUPLICATE:\t 62746\t(0.0, 1.0)\t0.442296345604\t0.229163241002\t0.23996918696869363\t-1.868598080707311\n\nHEADS\nDUPLICATE:\t 37254\t(0.0, 1.0)\t0.499143042344\t0.0781966093312\t0.37882622611424516\t-0.7513576897489256\nNOT DUPLICATE:\t 62746\t(0.0, 1.0)\t0.331432179202\t0.0858043118546\t0.9322872053274988\t-0.07576396293850074\n"
     ]
    }
   ],
   "source": [
    "subjects = defaultdict(list)\n",
    "objects = defaultdict(list)\n",
    "roots = defaultdict(list)\n",
    "heads = defaultdict(list)\n",
    "\n",
    "for pair_id, question1, question2, is_duplicate in train_set(100000):\n",
    "        question1_doc = nlp(question1)\n",
    "        question2_doc = nlp(question2)\n",
    "\n",
    "        subjects[is_duplicate].append(jaccard_index(get_subjects(question1_doc), get_subjects(question2_doc)))\n",
    "        objects[is_duplicate].append(jaccard_index(get_objects(question1_doc), get_objects(question2_doc)))\n",
    "        roots[is_duplicate].append(jaccard_index(get_roots(question1_doc), get_roots(question2_doc)))\n",
    "        heads[is_duplicate].append(jaccard_index(get_heads(question1_doc), get_heads(question2_doc)))\n",
    "\n",
    "print('\\tnumber of observations\\t(minimum, maximum)\\tmean\\tvariance\\tskewness\\tkurtosis')\n",
    "print('SUBJECTS')\n",
    "print('DUPLICATE:\\t', '\\t'.join(map(str, describe(subjects[1]))))\n",
    "print('NOT DUPLICATE:\\t', '\\t'.join(map(str, describe(subjects[0]))))\n",
    "print('\\nOBJECTS')\n",
    "print('DUPLICATE:\\t', '\\t'.join(map(str, describe(objects[1]))))\n",
    "print('NOT DUPLICATE:\\t', '\\t'.join(map(str, describe(objects[0]))))\n",
    "print('\\nROOTS')\n",
    "print('DUPLICATE:\\t', '\\t'.join(map(str, describe(roots[1]))))\n",
    "print('NOT DUPLICATE:\\t', '\\t'.join(map(str, describe(roots[0]))))\n",
    "print('\\nHEADS')\n",
    "print('DUPLICATE:\\t', '\\t'.join(map(str, describe(heads[1]))))\n",
    "print('NOT DUPLICATE:\\t', '\\t'.join(map(str, describe(heads[0]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}